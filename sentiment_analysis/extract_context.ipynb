{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-14T08:40:26.358537Z",
     "start_time": "2024-06-14T08:40:24.206142400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (4.40.2)\n",
      "Requirement already satisfied: torch in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (2.3.0+cu121)\n",
      "Requirement already satisfied: filelock in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (0.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (2024.4.16)\n",
      "Requirement already satisfied: requests in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from torch) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch) (2021.12.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\viksu\\desktop\\diploma\\topicextractor\\venv\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "!pip install transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\viksu\\Desktop\\Diploma\\TopicExtractor\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# Load pre-trained BERT model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to compute sentence embeddings\n",
    "def get_sentence_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T08:40:31.571206800Z",
     "start_time": "2024-06-14T08:40:27.249988500Z"
    }
   },
   "id": "fa2dfa725a67b08e"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def extract_context(text, topics, window_size=5):\n",
    "    \"\"\"\n",
    "    Extract context of given topics from text using token-based approach.\n",
    "    \n",
    "    Parameters:\n",
    "    - text (str): The input text.\n",
    "    - topics (dict): Dictionary with topics as keys and lists of keywords as values.\n",
    "    - window_size (int): Number of tokens to include before and after the topic keyword.\n",
    "    \n",
    "    Returns:\n",
    "    - dict: Dictionary with topics as keys and list of contexts as values.\n",
    "    \"\"\"\n",
    "    # Process the text\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.text for token in doc]\n",
    "    topic_positions = {topic: [] for topic in topics}\n",
    "    \n",
    "    for topic, phrases in topics.items():\n",
    "        for phrase in phrases:\n",
    "            phrase_tokens = phrase.split()\n",
    "            n = len(phrase_tokens)\n",
    "            \n",
    "            for i in range(len(tokens) - n + 1):\n",
    "                ngram_tokens = tokens[i:i + n]\n",
    "                \n",
    "                if ngram_tokens == phrase_tokens:\n",
    "                    topic_positions[topic].append(i)\n",
    "    \n",
    "    return topic_positions"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T09:42:07.776778600Z",
     "start_time": "2024-06-14T09:42:07.549357300Z"
    }
   },
   "id": "c21692fe284a087a"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contexts for topic 'equity market':\n",
      "15\n",
      "---\n",
      "Contexts for topic 'bond':\n",
      "42\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"The month of February offered divergent performance across\n",
    "the asset classes. While the equity market had a positive\n",
    "month, mainly driven by a handful of IT, high growth stocks,\n",
    "(i.e. Nvidia), the bond market ended in negative territory, as\n",
    "ratesâ€™ cuts expectations moved further out into the year.\n",
    "Strong economic data in the US and a good reporting season,\n",
    "especially within IT, developed market (DM) equities delivered\n",
    "a strong positive performance, while China-driven emerging\n",
    "markets (EM) did even better. Sector-wise, cyclicals clearly\n",
    "outperformed their more defensive peers, as Cons.\n",
    "Discretionary, IT and Industrials led the way, while Healthcare,\n",
    "Cons. Staples and Utilities lagged significantly. In terms of\n",
    "styles, Quality, Momentum and Growth outperformed Value\n",
    "and Low Risk. Within fixed income, curves flattened marginally\n",
    "and yields moved upwards around 30-40 bps on both sides of\n",
    "the Atlantic. Credit-wise, spreads moved down markedly\n",
    "across the board, with US investment grade being the only\n",
    "exception. \"\"\"\n",
    "\n",
    "topics = {\n",
    "    \"equity market\": [\"equity market\"],\n",
    "    \"bond\": [\"bond\", \"bonds\"],\n",
    "}\n",
    "\n",
    "contexts = extract_context(text, topics, window_size=5)\n",
    "for topic, context_list in contexts.items():\n",
    "    print(f\"Contexts for topic '{topic}':\")\n",
    "    for context in context_list:\n",
    "        print(context)\n",
    "        print(\"---\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-14T09:42:08.171812800Z",
     "start_time": "2024-06-14T09:42:08.139973300Z"
    }
   },
   "id": "8da23405dd074923"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "135daec01ca2c139"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
